# ğŸ©ºâ€¯Patient Poseâ€‘Estimation Pipeline

A lightweight Python system that **collects patient metadata, records
activity videos, and runs pose estimation** (Ultralytics YOLOâ€‘Nâ€‘Pose) on
each recording. All results are persisted in a clean, hierarchical JSON
database for later analysis.

<table>
<tr>
<td align="center"><b>PatientÂ â†’ SessionÂ â†’ ActivityÂ â†’ VideoÂ â†’ Keypoints</b></td>
<td>

```
database.json
â””â”€â”€ participants/
    â””â”€â”€ 265465/
        â”œâ”€â”€ name: "Todd"
        â”œâ”€â”€ age: 39
        â””â”€â”€ sessions/
            â””â”€â”€ 265465_1/
                â”œâ”€â”€ start_time
                â”œâ”€â”€ activities/
                â”‚   â”œâ”€â”€ 265465_1_1/ â† "A Pose"
                â”‚   â”‚   â””â”€â”€ video_recordings/
                â”‚   â”‚       â””â”€â”€ 265465_1_1_A_Pose_1/
                â”‚   â”‚           â”œâ”€â”€ metadata
                â”‚   â”‚           â””â”€â”€ keypoints
                â”‚   â””â”€â”€ 265465_1_2/ â† "Stationary Walking"
                â””â”€â”€ end_time
```

</td></tr></table>

---

## âœ¨ Features

| Module                        | What it does                                                                     |
| ----------------------------- | -------------------------------------------------------------------------------- |
| **`participant.py`**          | Registers a participant and spins up a new session                               |
| **`session.py`**              | Starts a session, triggers each activity in sequence                             |
| **`activity.py`**             | Defines activities (`A Pose`, `StationaryÂ Walking`) and attaches video recording |
| **`video_recording.py`**      | Records webcam / UDP stream toÂ `.mp4`, stores rich metadata                      |
| **`pose_estimation_data.py`** | Runs YOLOv8â€‘pose on every video, timestamps each frameâ€™s keypoints               |
| **`db.py`**                   | Thin JSON â€œDBâ€ wrapper with hierarchical update helper                           |
| **`requirements.txt`**        | Exact package list (Ultralytics, OpenCV, etc.)                                   |

---

## ğŸ“‚ Project Layout

```
â”œâ”€ activity.py
â”œâ”€ db.py
â”œâ”€ main.py
â”œâ”€ participant.py
â”œâ”€ pose_estimation_data.py
â”œâ”€ session.py
â”œâ”€ video_recording.py
â”œâ”€ requirements.txt
â”œâ”€ video_recordings/          # autoâ€‘created, stores .mp4 files
â””â”€ database.json              # autoâ€‘created, hierarchical patient DB
```

---

## ğŸš€ QuickÂ Start

1. **Clone & set up environment**

   ```bash
   git clone https://github.com/omerwer/Personal-projects
   cd Personal-projects/python/computer_vision_detection/ai_cv
   python -m venv .venv
   source .venv/bin/activate     # Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **(Optional) Download the pose model once**

   The first run of Ultralytics will autoâ€‘download `yolo11nâ€‘pose.pt`.
   For offline deployments, place it next to the scripts.

3. **Run the demo pipeline**

   ```bash
   # main.py records two activities for patient 265465, then
   # launches pose estimation on the captured videos.
   python main.py
   ```

4. **Inspect results**

   * `database.json` â€“ check the nested structure for timestamps,
     video metadata, and "keypoints" arrays
   * `video_recordings/*.mp4` â€“ raw recordings

---

## âš™ï¸ Configuration Highlights

| Setting                | Where                     | Default                        | Notes                               |
| ---------------------- | ------------------------- | ------------------------------ | ----------------------------------- |
| **Video source**       | `video_recording.py`      | `"udp://127.0.0.1:8090"`       | Change to `0` for local webcam      |
| **FPS / codec**        | `video_recording.py`      | 30â€¯FPS, `mp4v`                 | Tweak for quality vs. size          |
| **Model path**         | `pose_estimation_data.py` | `'yolo11n-pose.pt'`            | Could swap to any YOLOâ€‘pose variant |
| **Required durations** | `activity.py`             | `10â€¯s` (AÂ Pose), `30â€¯s` (Walk) | Stored in DB for validation         |

---

## ğŸ§  Flow Overview

```mermaid
graph TD
    subgraph Data Flow
      A([main.py]) -->|create| B[Participant]
      B --> C[Session]
      C -->|for act in ["A Pose", "Stationary Walking"]| D(Activity)
      D --> E[VideoRecording]
      E -->|.mp4 + metadata| DB[(JSON DB)]
      E -->|.mp4| F[PoseEstimationData]
      F -->|keypoints JSON| DB
    end
```

1. **Participant / Session** are created â†’ logged in `database.json`.
2. Each **Activity** starts a **VideoRecording** thread that writes a local
   `.mp4` and metadata (resolution, framerate, duration, frame drops).
3. After recording finishes, **PoseEstimationData** iterates every video,
   runs YOLOâ€‘pose frameâ€‘byâ€‘frame, stores 2â€‘D keypoints alongside each
   timestamp.
4. Keypoints are merged back into the same nested path in the DB.                                                        |

---

## ğŸ“œ License

Distributed under the MIT License
